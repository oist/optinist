{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a31d0d3c",
   "metadata": {},
   "source": [
    "`conda env create -n suite2p_env -f optinist/conda/suite2p_env.yaml`\n",
    "\n",
    "`!pip install imageio pynwb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ebe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from studio.wrappers.suite2p import file_convert, registration, roi\n",
    "from studio.dataclass import ImageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = ImageData(['../sample_data/mouse2p_2_donotouse.tiff'], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b86eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_convert_params = {\n",
    "    'nplanes': 1,\n",
    "    'nchannels': 1,\n",
    "    'force_sktiff': False,\n",
    "    'batch_size': 500,\n",
    "    'do_registration': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000581b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret = file_convert.suite2p_file_convert(sample_data, file_convert_params)\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_params = {\n",
    "    'frames_include': -1,\n",
    "    'keep_movie_raw': False,\n",
    "    'do_bidiphase': False,\n",
    "\n",
    "    'smooth_sigma': 1.15,\n",
    "    'smooth_sigma_time': 0,\n",
    "    'bidiphase': 0,\n",
    "    'maxregshift': 0.1,\n",
    "    'maxregshiftNR': 5,\n",
    "    'nonrigid': True,\n",
    "    'block_size': [128, 128],\n",
    "    'snr_thresh': 1.2,\n",
    "    'functional_chan' : 1,\n",
    "    'align_by_chan' : 1,\n",
    "    'reg_tif': False,\n",
    "    'th_badframes': 1.0,\n",
    "    'diameter': 0,\n",
    "\n",
    "    # 1P setting\n",
    "    '1Preg': False,\n",
    "    'spatial_hp_reg': 42,\n",
    "    'pre_smooth': 0,\n",
    "    'spatial_taper': 40,\n",
    "    'bidi_corrected': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c87d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = registration.suite2p_registration(ret['ops'], registration_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb844d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite2p_roi_params = {\n",
    "    # main settings\n",
    "    'tau':  1.0,              # this is the main parameter for deconvolution\n",
    "    'fs': 10.0,             # sampling rate (PER PLANE e.g. for 12 plane recordings it will be around 2.5)\n",
    "\n",
    "    # classification parameters\n",
    "    'soma_crop': True,        # crop dendrites for cell classification stats like compactness\n",
    "\n",
    "    # cell detection settings\n",
    "    'high_pass': 100,         # running mean subtraction with window of size 'high_pass(use low values for 1P)\n",
    "    'sparse_mode': True,      # whether or not to run sparse_mode\n",
    "    'max_overlap': 0.75,      # cells with more overlap than this get removed during triage before refinement\n",
    "    'nbinned': 5000,          # max number of binned frames for cell detection\n",
    "    'spatial_scale': 0,       # 0: multi-scale; 1: 6 pixels 2: 12 pixels 3: 24 pixels 4: 48 pixels\n",
    "    'threshold_scaling': 1.0, # adjust the automatically determined threshold by this scalar multiplier\n",
    "    'max_iterations': 20,     # maximum number of iterations to do cell detection\n",
    "\n",
    "    # 1P settings\n",
    "    'spatial_hp_detect': 25,  # window for spatial high-pass filtering for neuropil subtraction before detection\n",
    "\n",
    "    # output settings\n",
    "    'preclassify': 0.,       # apply classifier before signal extraction with probability 0.3\n",
    "\n",
    "    # ROI extraction parameters\n",
    "    'allow_overlap': False,      # pixels that are overlapping are thrown out (False) or added to both ROIs (True)\n",
    "    'inner_neuropil_radius': 2,  # number of pixels to keep between ROI and neuropil donut\n",
    "    'min_neuropil_pixels': 350,  # minimum number of pixels in the neuropil\n",
    "\n",
    "    # deconvolution settings\n",
    "    'neucoeff': .7,          # neuropil coefficient\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb91557",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = roi.suite2p_roi(ret['ops'], suite2p_roi_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b562d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for roi in ret['nwbfile']['ROI']['roi_list']:\n",
    "    print(roi.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
